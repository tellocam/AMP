\section*{Task Description - To Remove before Submission heheh}
\begin{itemize}
    \item 4 Datasets (2x from ex0, 2x from Kaggle TU Wien Informatics)
    \item Run 3 different Classifiers on all four datasets ($4 \cdot 3 = 12$ classifiers, yes integer arithmetic very hard)
    \item Choice of classifiers:
    \begin{enumerate}
    \item Use classifiers from different paradigms. e.g.: dont use only tre based algorithms
    \item Use classifiers from already covered, not yet covered or not at all covered in the ML lecture 
    \end{enumerate}
    \item Different Parameter Settings (Several results per classifier and dataset, not only random/best)
    \item Evaluate and analyze performance
    \item Make valid comparisons, e.g. across datasets, across classifiers
    \item How do results change when preprocessing strategies change? (explain impact, mainly scaling)
    \item Compare Holdout to Cross-Validation
    \item find multiple means of performance measures for classifiers
    \item Argue on choice of Performance Measures
    \item Argue on measures we took to ensure comparability of classifier performance
\end{itemize}

\section{Classifiers and Performance Metrics}
\subsection*{Classifiers}
In task 1 of the machine learning course, we had to implement 3 different classification algorithms from 3 different
classification paradigms:
\begin{itemize}
    \item Bayesian Network Algorithm
    \item MLP Network Algorithm
    \item k-NN
\end{itemize}